{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Block 6 Exercise 1: Non-Linear Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Data\n",
    "We return to the MNIST data set on handwritten digits to compare non-linear classification algorithms ...   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from https://www.openml.org/d/554\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the full MNIST data set contains 70k samples of digits 0-9 as 28*28 gray scale images (represented as 784 dim vectors)\n",
    "np.shape(X)\n",
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pixel1      0.0\n",
       "pixel2      0.0\n",
       "pixel3      0.0\n",
       "pixel4      0.0\n",
       "pixel5      0.0\n",
       "           ... \n",
       "pixel780    0.0\n",
       "pixel781    0.0\n",
       "pixel782    0.0\n",
       "pixel783    0.0\n",
       "pixel784    0.0\n",
       "Length: 784, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pixel1       0.0\n",
       "pixel2       0.0\n",
       "pixel3       0.0\n",
       "pixel4       0.0\n",
       "pixel5       0.0\n",
       "            ... \n",
       "pixel780    62.0\n",
       "pixel781     0.0\n",
       "pixel782     0.0\n",
       "pixel783     0.0\n",
       "pixel784     0.0\n",
       "Length: 784, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look at max/min value in the data\n",
    "X.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E1.1: Cross-Validation and Support Vector Machines\n",
    "Train and optimize  C-SVM classifier on MNIST (https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC)\n",
    "* use a RBF kernel\n",
    "* use *random search* with cross-validation to find the best settings for *gamma* and *C* (https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=40).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7217678571428572\n",
      "0.7225\n",
      "Wall time: 4min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "\n",
    "clf_svm = make_pipeline(StandardScaler(),SVC(C = 1.0, kernel='rbf', gamma = 'auto', max_iter=40, random_state=42))\n",
    "clf_svm.fit(X_train, y_train)\n",
    "y_pred_train = clf_svm.predict(X_train)\n",
    "y_pred_test = clf_svm.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_train, y_pred_train))\n",
    "print(accuracy_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\"\n",
    "                  .format(results['mean_test_score'][candidate],\n",
    "                          results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 3207.80 seconds for 10 candidate parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.835 (std: 0.013)\n",
      "Parameters: {'gamma': 0.004291428571428571, 'C': 1.0}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.817 (std: 0.009)\n",
      "Parameters: {'gamma': 0.005005, 'C': 0.5555555555555556}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.810 (std: 0.006)\n",
      "Parameters: {'gamma': 0.0028642857142857146, 'C': 0.4444444444444444}\n",
      "\n",
      "0.8131964285714286\n",
      "0.8011428571428572\n",
      "Wall time: 58min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from time import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "clf_svm = SVC(max_iter = 50, random_state = 42)\n",
    "\n",
    "# use a full grid over all parameters\n",
    "param_grid = {'C': np.linspace(0, 1, num=10),\n",
    "              'gamma': np.linspace(0.00001, 0.01, num=15)}\n",
    "\n",
    "# run grid search\n",
    "SVM_random_search = RandomizedSearchCV(estimator= clf_svm, param_distributions = param_grid, cv = 4, random_state=42)\n",
    "start = time()\n",
    "SVM_random_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "      % (time() - start, len(SVM_random_search.cv_results_['params'])))\n",
    "report(SVM_random_search.cv_results_)\n",
    "\n",
    "y_pred_train = SVM_random_search.predict(X_train)\n",
    "y_pred_test = SVM_random_search.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_train, y_pred_train))\n",
    "print(accuracy_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E1.2: Pipelines and simple Neural Networks\n",
    "Split the MNIST data into  train- and test-sets and then train and evaluate a simple Multi Layer Perceptron (MLP) network. Since the non-linear activation functions of MLPs are sensitive to the scaling on the input (recall the *sigmoid* function), we need to scale all input values to [0,1] \n",
    "\n",
    "* combine all steps of your training in a SKL pipeline (https://scikit-learn.org/stable/modules/compose.html#pipeline)\n",
    "* use a SKL-scaler to scale the data (https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)\n",
    "* MLP Parameters: https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier\n",
    "    * use a *SGD* solver\n",
    "    * use *tanh* as activation function\n",
    "    * compare networks with 1, 2 and 3 layers, use different numbers of neurons per layer\n",
    "    * adjust training parameters *alpha* (regularization) and *learning rate* - how sensitive is the model to these parameters?\n",
    "    * Hint: do not change all parameters at the same time, split into several experiments\n",
    "* How hard is it to find the best parameters? How many experiments would you need to find the best parameters?\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Parameter Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (250) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score with train data:  0.37141071428571426\n",
      "accuracy score with test data :  0.3725\n",
      "f1 score with train data:  0.29783460600101647\n",
      "f1 score with test data :  0.29649149230806626\n",
      "Wall time: 6min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf_MLP_1 = make_pipeline(StandardScaler(), MLPClassifier(hidden_layer_sizes = 1, activation = 'tanh', \n",
    "                                                        solver = 'sgd', alpha = 0.0001, learning_rate = 'constant', \n",
    "                                                        max_iter=250, random_state=42))\n",
    "clf_MLP_1.fit(X_train, y_train)\n",
    "y_pred_train = clf_MLP_1.predict(X_train)\n",
    "y_pred_test = clf_MLP_1.predict(X_test)\n",
    "\n",
    "print('accuracy score with train data: ', accuracy_score(y_train, y_pred_train))\n",
    "print('accuracy score with test data : ', accuracy_score(y_test, y_pred_test))\n",
    "print('f1 score with train data: ', f1_score(y_train, y_pred_train, average='macro'))\n",
    "print('f1 score with test data : ', f1_score(y_test, y_pred_test, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Parameter Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (250) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score with train data:  0.6196785714285714\n",
      "accuracy score with test data :  0.608\n",
      "f1 score with train data:  0.5969268646705529\n",
      "f1 score with test data :  0.5835539061752788\n",
      "Wall time: 7min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf_MLP_2 = make_pipeline(StandardScaler(), MLPClassifier(hidden_layer_sizes = 2, activation = 'tanh', \n",
    "                                                        solver = 'sgd', alpha = 0.0001, learning_rate = 'constant', \n",
    "                                                        max_iter=250, random_state=42))\n",
    "clf_MLP_2.fit(X_train, y_train)\n",
    "y_pred_train = clf_MLP_2.predict(X_train)\n",
    "y_pred_test = clf_MLP_2.predict(X_test)\n",
    "\n",
    "print('accuracy score with train data: ', accuracy_score(y_train, y_pred_train))\n",
    "print('accuracy score with test data : ', accuracy_score(y_test, y_pred_test))\n",
    "print('f1 score with train data: ', f1_score(y_train, y_pred_train, average='macro'))\n",
    "print('f1 score with test data : ', f1_score(y_test, y_pred_test, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Parameter Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (250) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score with train data:  0.770625\n",
      "accuracy score with test data :  0.7568571428571429\n",
      "f1 score with train data:  0.7609884104295912\n",
      "f1 score with test data :  0.7467334214103711\n",
      "Wall time: 5min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf_MLP_3 = make_pipeline(StandardScaler(), MLPClassifier(hidden_layer_sizes = 3, activation = 'tanh', \n",
    "                                                        solver = 'sgd', alpha = 0.01, learning_rate = 'constant', \n",
    "                                                        max_iter=250, random_state=42))\n",
    "clf_MLP_3.fit(X_train, y_train)\n",
    "y_pred_train = clf_MLP_3.predict(X_train)\n",
    "y_pred_test = clf_MLP_3.predict(X_test)\n",
    "\n",
    "print('accuracy score with train data: ', accuracy_score(y_train, y_pred_train))\n",
    "print('accuracy score with test data : ', accuracy_score(y_test, y_pred_test))\n",
    "print('f1 score with train data: ', f1_score(y_train, y_pred_train, average='macro'))\n",
    "print('f1 score with test data : ', f1_score(y_test, y_pred_test, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Parameter Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score with train data:  0.4200357142857143\n",
      "accuracy score with test data :  0.4184285714285714\n",
      "f1 score with train data:  0.3021556731325291\n",
      "f1 score with test data :  0.3019010094808761\n",
      "Wall time: 1min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf_MLP_4 = make_pipeline(StandardScaler(), MLPClassifier(hidden_layer_sizes = 3, activation = 'tanh', \n",
    "                                                        solver = 'sgd', alpha = 0.00001, learning_rate = 'invscaling', \n",
    "                                                        max_iter=250, random_state=42))\n",
    "clf_MLP_4.fit(X_train, y_train)\n",
    "y_pred_train = clf_MLP_4.predict(X_train)\n",
    "y_pred_test = clf_MLP_4.predict(X_test)\n",
    "\n",
    "print('accuracy score with train data: ', accuracy_score(y_train, y_pred_train))\n",
    "print('accuracy score with test data : ', accuracy_score(y_test, y_pred_test))\n",
    "print('f1 score with train data: ', f1_score(y_train, y_pred_train, average='macro'))\n",
    "print('f1 score with test data : ', f1_score(y_test, y_pred_test, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Parameter Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (250) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score with train data:  0.7706428571428572\n",
      "accuracy score with test data :  0.7572142857142857\n",
      "f1 score with train data:  0.7612512999890869\n",
      "f1 score with test data :  0.7473287422422983\n",
      "Wall time: 5min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf_MLP_5 = make_pipeline(StandardScaler(), MLPClassifier(hidden_layer_sizes = 3, activation = 'tanh', \n",
    "                                                        solver = 'sgd', alpha = 0.000001, learning_rate = 'adaptive', \n",
    "                                                        max_iter=250, random_state=42))\n",
    "clf_MLP_5.fit(X_train, y_train)\n",
    "y_pred_train = clf_MLP_5.predict(X_train)\n",
    "y_pred_test = clf_MLP_5.predict(X_test)\n",
    "\n",
    "print('accuracy score with train data: ', accuracy_score(y_train, y_pred_train))\n",
    "print('accuracy score with test data : ', accuracy_score(y_test, y_pred_test))\n",
    "print('f1 score with train data: ', f1_score(y_train, y_pred_train, average='macro'))\n",
    "print('f1 score with test data : ', f1_score(y_test, y_pred_test, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
